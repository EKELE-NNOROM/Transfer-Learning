{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "Dataset already downloaded. Did not download twice.\n",
      "\n",
      "Extracting...\n",
      "Dataset already extracted. Did not extract twice.\n",
      "\n",
      "Current directory C:\\Users\\Ekele\\Desktop\\TransferLearning\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"data\"\n",
    "os.chdir(DATA_PATH)\n",
    "%run download.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hymenoptera_data Dataset is now located at data\\hymenoptera_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train', 'val']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join(DATA_PATH, \"hymenoptera_data\")\n",
    " \n",
    "print(\"\\n\" + \"hymenoptera_data Dataset is now located at {}\".format(DATASET_PATH))\n",
    "os.listdir(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATASET_PATH, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                \n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        \n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nn.Sequential(*list(model_conv.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_conv.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-11           [-1, 64, 64, 64]               0\n",
      "           Conv2d-12           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 64, 64]             128\n",
      "             ReLU-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 64, 64]             128\n",
      "             ReLU-17           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-18           [-1, 64, 64, 64]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "           Conv2d-24          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 32, 32]             256\n",
      "             ReLU-26          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "             ReLU-30          [-1, 128, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,176,512\n",
      "Trainable params: 11,176,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 82.00\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 125.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(decoder.cuda(), (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_50 = torchvision.models.resnet50(pretrained=True)\n",
    "encoder50 = nn.Sequential(*list(model_conv.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-11           [-1, 64, 64, 64]               0\n",
      "           Conv2d-12           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 64, 64]             128\n",
      "             ReLU-14           [-1, 64, 64, 64]               0\n",
      "           Conv2d-15           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 64, 64]             128\n",
      "             ReLU-17           [-1, 64, 64, 64]               0\n",
      "       BasicBlock-18           [-1, 64, 64, 64]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
      "           Conv2d-24          [-1, 128, 32, 32]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 32, 32]             256\n",
      "             ReLU-26          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
      "             ReLU-30          [-1, 128, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,176,512\n",
      "Trainable params: 11,176,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 82.00\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 125.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(encoder50.cuda(), (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_input, n_output, dropout=0.0):\n",
    "        super(Decoder, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(n_input, n_output, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(n_output),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(GeneratorUNet, self).__init__()\n",
    "        \n",
    "\n",
    "        self.up1 = Decoder(512, 512, dropout=0.5)\n",
    "        self.up2 = Decoder(512, 256, dropout=0.5)\n",
    "        self.up3 = Decoder(256, 256, dropout=0.5)\n",
    "        self.up4 = Decoder(256, 128, dropout=0.5)\n",
    "        self.up5 = Decoder(128, 128)\n",
    "#         self.up6 = Decoder(512, 128)\n",
    "#         self.up7 = Decoder(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 3, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        \n",
    "        u1 = self.up1(x)\n",
    "        u2 = self.up2(u1)\n",
    "        u3 = self.up3(u2)\n",
    "        u4 = self.up4(u3)\n",
    "        u5 = self.up5(u4)\n",
    "        \n",
    "\n",
    "        return self.final(u5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder50 = GeneratorUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1          [-1, 512, 16, 16]       4,194,304\n",
      "    InstanceNorm2d-2          [-1, 512, 16, 16]               0\n",
      "              ReLU-3          [-1, 512, 16, 16]               0\n",
      "           Dropout-4          [-1, 512, 16, 16]               0\n",
      "           Decoder-5          [-1, 512, 16, 16]               0\n",
      "   ConvTranspose2d-6          [-1, 256, 32, 32]       2,097,152\n",
      "    InstanceNorm2d-7          [-1, 256, 32, 32]               0\n",
      "              ReLU-8          [-1, 256, 32, 32]               0\n",
      "           Dropout-9          [-1, 256, 32, 32]               0\n",
      "          Decoder-10          [-1, 256, 32, 32]               0\n",
      "  ConvTranspose2d-11          [-1, 256, 64, 64]       1,048,576\n",
      "   InstanceNorm2d-12          [-1, 256, 64, 64]               0\n",
      "             ReLU-13          [-1, 256, 64, 64]               0\n",
      "          Dropout-14          [-1, 256, 64, 64]               0\n",
      "          Decoder-15          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-16        [-1, 128, 128, 128]         524,288\n",
      "   InstanceNorm2d-17        [-1, 128, 128, 128]               0\n",
      "             ReLU-18        [-1, 128, 128, 128]               0\n",
      "          Dropout-19        [-1, 128, 128, 128]               0\n",
      "          Decoder-20        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-21        [-1, 128, 256, 256]         262,144\n",
      "   InstanceNorm2d-22        [-1, 128, 256, 256]               0\n",
      "             ReLU-23        [-1, 128, 256, 256]               0\n",
      "          Decoder-24        [-1, 128, 256, 256]               0\n",
      "           Conv2d-25          [-1, 3, 256, 256]           3,459\n",
      "             Tanh-26          [-1, 3, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 8,129,923\n",
      "Trainable params: 8,129,923\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 394.00\n",
      "Params size (MB): 31.01\n",
      "Estimated Total Size (MB): 425.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(decoder50.cuda(), (512, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
      "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
      "             ReLU-15          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
      "           Conv2d-17           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
      "             ReLU-19           [-1, 64, 64, 64]               0\n",
      "           Conv2d-20           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 64, 64]             128\n",
      "             ReLU-22           [-1, 64, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
      "             ReLU-29           [-1, 64, 64, 64]               0\n",
      "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
      "             ReLU-32           [-1, 64, 64, 64]               0\n",
      "           Conv2d-33          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
      "             ReLU-35          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
      "           Conv2d-37          [-1, 128, 64, 64]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 64, 64]             256\n",
      "             ReLU-39          [-1, 128, 64, 64]               0\n",
      "           Conv2d-40          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
      "             ReLU-42          [-1, 128, 32, 32]               0\n",
      "           Conv2d-43          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-47          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 32, 32]             256\n",
      "             ReLU-51          [-1, 128, 32, 32]               0\n",
      "           Conv2d-52          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 32, 32]             256\n",
      "             ReLU-54          [-1, 128, 32, 32]               0\n",
      "           Conv2d-55          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-57          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
      "           Conv2d-59          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
      "             ReLU-61          [-1, 128, 32, 32]               0\n",
      "           Conv2d-62          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 32, 32]             256\n",
      "             ReLU-64          [-1, 128, 32, 32]               0\n",
      "           Conv2d-65          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-67          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
      "           Conv2d-69          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 32, 32]             256\n",
      "             ReLU-71          [-1, 128, 32, 32]               0\n",
      "           Conv2d-72          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 32, 32]             256\n",
      "             ReLU-74          [-1, 128, 32, 32]               0\n",
      "           Conv2d-75          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-77          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
      "           Conv2d-79          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 32, 32]             512\n",
      "             ReLU-81          [-1, 256, 32, 32]               0\n",
      "           Conv2d-82          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 16, 16]             512\n",
      "             ReLU-84          [-1, 256, 16, 16]               0\n",
      "           Conv2d-85         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
      "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-89         [-1, 1024, 16, 16]               0\n",
      "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-91          [-1, 256, 16, 16]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 16, 16]             512\n",
      "             ReLU-93          [-1, 256, 16, 16]               0\n",
      "           Conv2d-94          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 16, 16]             512\n",
      "             ReLU-96          [-1, 256, 16, 16]               0\n",
      "           Conv2d-97         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-99         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-101          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 16, 16]             512\n",
      "            ReLU-103          [-1, 256, 16, 16]               0\n",
      "          Conv2d-104          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 16, 16]             512\n",
      "            ReLU-106          [-1, 256, 16, 16]               0\n",
      "          Conv2d-107         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-109         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-111          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 16, 16]             512\n",
      "            ReLU-113          [-1, 256, 16, 16]               0\n",
      "          Conv2d-114          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
      "            ReLU-116          [-1, 256, 16, 16]               0\n",
      "          Conv2d-117         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-119         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
      "            ReLU-123          [-1, 256, 16, 16]               0\n",
      "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
      "            ReLU-126          [-1, 256, 16, 16]               0\n",
      "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-129         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
      "            ReLU-133          [-1, 256, 16, 16]               0\n",
      "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
      "            ReLU-136          [-1, 256, 16, 16]               0\n",
      "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-139         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-141          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-143          [-1, 512, 16, 16]               0\n",
      "          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-146            [-1, 512, 8, 8]               0\n",
      "          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n",
      "          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-151           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-152           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-155            [-1, 512, 8, 8]               0\n",
      "          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-158            [-1, 512, 8, 8]               0\n",
      "          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-161           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-162           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-165            [-1, 512, 8, 8]               0\n",
      "          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-168            [-1, 512, 8, 8]               0\n",
      "          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-171           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-172           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 374.27\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 472.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_conv_50 = torchvision.models.resnet50(pretrained=True)\n",
    "summary(model_conv_50.cuda(), (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
      "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
      "             ReLU-15          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
      "           Conv2d-17           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
      "             ReLU-19           [-1, 64, 64, 64]               0\n",
      "           Conv2d-20           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 64, 64]             128\n",
      "             ReLU-22           [-1, 64, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
      "             ReLU-29           [-1, 64, 64, 64]               0\n",
      "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
      "             ReLU-32           [-1, 64, 64, 64]               0\n",
      "           Conv2d-33          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
      "             ReLU-35          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
      "           Conv2d-37          [-1, 128, 64, 64]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 64, 64]             256\n",
      "             ReLU-39          [-1, 128, 64, 64]               0\n",
      "           Conv2d-40          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
      "             ReLU-42          [-1, 128, 32, 32]               0\n",
      "           Conv2d-43          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-47          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 32, 32]             256\n",
      "             ReLU-51          [-1, 128, 32, 32]               0\n",
      "           Conv2d-52          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 32, 32]             256\n",
      "             ReLU-54          [-1, 128, 32, 32]               0\n",
      "           Conv2d-55          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-57          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
      "           Conv2d-59          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
      "             ReLU-61          [-1, 128, 32, 32]               0\n",
      "           Conv2d-62          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 32, 32]             256\n",
      "             ReLU-64          [-1, 128, 32, 32]               0\n",
      "           Conv2d-65          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-67          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
      "           Conv2d-69          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 32, 32]             256\n",
      "             ReLU-71          [-1, 128, 32, 32]               0\n",
      "           Conv2d-72          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 32, 32]             256\n",
      "             ReLU-74          [-1, 128, 32, 32]               0\n",
      "           Conv2d-75          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-77          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
      "           Conv2d-79          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 32, 32]             512\n",
      "             ReLU-81          [-1, 256, 32, 32]               0\n",
      "           Conv2d-82          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 16, 16]             512\n",
      "             ReLU-84          [-1, 256, 16, 16]               0\n",
      "           Conv2d-85         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
      "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-89         [-1, 1024, 16, 16]               0\n",
      "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-91          [-1, 256, 16, 16]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 16, 16]             512\n",
      "             ReLU-93          [-1, 256, 16, 16]               0\n",
      "           Conv2d-94          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 16, 16]             512\n",
      "             ReLU-96          [-1, 256, 16, 16]               0\n",
      "           Conv2d-97         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-99         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-101          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 16, 16]             512\n",
      "            ReLU-103          [-1, 256, 16, 16]               0\n",
      "          Conv2d-104          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 16, 16]             512\n",
      "            ReLU-106          [-1, 256, 16, 16]               0\n",
      "          Conv2d-107         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-109         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-111          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 16, 16]             512\n",
      "            ReLU-113          [-1, 256, 16, 16]               0\n",
      "          Conv2d-114          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
      "            ReLU-116          [-1, 256, 16, 16]               0\n",
      "          Conv2d-117         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-119         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
      "            ReLU-123          [-1, 256, 16, 16]               0\n",
      "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
      "            ReLU-126          [-1, 256, 16, 16]               0\n",
      "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-129         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
      "            ReLU-133          [-1, 256, 16, 16]               0\n",
      "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
      "            ReLU-136          [-1, 256, 16, 16]               0\n",
      "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-139         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-141          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-143          [-1, 512, 16, 16]               0\n",
      "          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-146            [-1, 512, 8, 8]               0\n",
      "          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n",
      "          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-151           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-152           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-155            [-1, 512, 8, 8]               0\n",
      "          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-158            [-1, 512, 8, 8]               0\n",
      "          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-161           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-162           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-165            [-1, 512, 8, 8]               0\n",
      "          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-168            [-1, 512, 8, 8]               0\n",
      "          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-171           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-172           [-1, 2048, 8, 8]               0\n",
      "================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 374.25\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 464.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "encoder50 = nn.Sequential(*list(model_conv_50.children())[:-2])\n",
    "summary(encoder50.cuda(), (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(nn.Module):\n",
    "    def __init__(self, model, out_channels=3):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        \n",
    "        #self.encoder = model\n",
    "        self.encoder50 = nn.Sequential(*list(model_conv.children())[:-2])\n",
    "        for param in self.encoder50.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.up1 = Decoder(512, 512, dropout=0.5)\n",
    "        self.up2 = Decoder(512, 256, dropout=0.5)\n",
    "        self.up3 = Decoder(256, 256, dropout=0.5)\n",
    "        self.up4 = Decoder(256, 128, dropout=0.5)\n",
    "        self.up5 = Decoder(128, 128)\n",
    "#         self.up6 = Decoder(512, 128)\n",
    "#         self.up7 = Decoder(256, 64)\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 3, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # U-Net generator with skip connections from encoder to decoder\n",
    "        x = self.encoder50(x)\n",
    "        u1 = self.up1(x)\n",
    "        u2 = self.up2(u1)\n",
    "        u3 = self.up3(u2)\n",
    "        u4 = self.up4(u3)\n",
    "        u5 = self.up5(u4)\n",
    "        \n",
    "\n",
    "        return self.final(u5)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
      "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
      "             ReLU-15          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
      "           Conv2d-17           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 64, 64]             128\n",
      "             ReLU-19           [-1, 64, 64, 64]               0\n",
      "           Conv2d-20           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 64, 64]             128\n",
      "             ReLU-22           [-1, 64, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 64, 64]             128\n",
      "             ReLU-29           [-1, 64, 64, 64]               0\n",
      "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 64, 64]             128\n",
      "             ReLU-32           [-1, 64, 64, 64]               0\n",
      "           Conv2d-33          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
      "             ReLU-35          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
      "           Conv2d-37          [-1, 128, 64, 64]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 64, 64]             256\n",
      "             ReLU-39          [-1, 128, 64, 64]               0\n",
      "           Conv2d-40          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 32, 32]             256\n",
      "             ReLU-42          [-1, 128, 32, 32]               0\n",
      "           Conv2d-43          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-47          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 32, 32]             256\n",
      "             ReLU-51          [-1, 128, 32, 32]               0\n",
      "           Conv2d-52          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 32, 32]             256\n",
      "             ReLU-54          [-1, 128, 32, 32]               0\n",
      "           Conv2d-55          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-57          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
      "           Conv2d-59          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 32, 32]             256\n",
      "             ReLU-61          [-1, 128, 32, 32]               0\n",
      "           Conv2d-62          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 32, 32]             256\n",
      "             ReLU-64          [-1, 128, 32, 32]               0\n",
      "           Conv2d-65          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-67          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
      "           Conv2d-69          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 32, 32]             256\n",
      "             ReLU-71          [-1, 128, 32, 32]               0\n",
      "           Conv2d-72          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 32, 32]             256\n",
      "             ReLU-74          [-1, 128, 32, 32]               0\n",
      "           Conv2d-75          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-77          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
      "           Conv2d-79          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 32, 32]             512\n",
      "             ReLU-81          [-1, 256, 32, 32]               0\n",
      "           Conv2d-82          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 16, 16]             512\n",
      "             ReLU-84          [-1, 256, 16, 16]               0\n",
      "           Conv2d-85         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
      "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-89         [-1, 1024, 16, 16]               0\n",
      "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-91          [-1, 256, 16, 16]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 16, 16]             512\n",
      "             ReLU-93          [-1, 256, 16, 16]               0\n",
      "           Conv2d-94          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 16, 16]             512\n",
      "             ReLU-96          [-1, 256, 16, 16]               0\n",
      "           Conv2d-97         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-99         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-101          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 16, 16]             512\n",
      "            ReLU-103          [-1, 256, 16, 16]               0\n",
      "          Conv2d-104          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 16, 16]             512\n",
      "            ReLU-106          [-1, 256, 16, 16]               0\n",
      "          Conv2d-107         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-109         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-111          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 16, 16]             512\n",
      "            ReLU-113          [-1, 256, 16, 16]               0\n",
      "          Conv2d-114          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
      "            ReLU-116          [-1, 256, 16, 16]               0\n",
      "          Conv2d-117         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-119         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
      "            ReLU-123          [-1, 256, 16, 16]               0\n",
      "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
      "            ReLU-126          [-1, 256, 16, 16]               0\n",
      "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-129         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-131          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 16, 16]             512\n",
      "            ReLU-133          [-1, 256, 16, 16]               0\n",
      "          Conv2d-134          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 16, 16]             512\n",
      "            ReLU-136          [-1, 256, 16, 16]               0\n",
      "          Conv2d-137         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-139         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-141          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-143          [-1, 512, 16, 16]               0\n",
      "          Conv2d-144            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-146            [-1, 512, 8, 8]               0\n",
      "          Conv2d-147           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 8, 8]           4,096\n",
      "          Conv2d-149           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-151           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-152           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-153            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-155            [-1, 512, 8, 8]               0\n",
      "          Conv2d-156            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-158            [-1, 512, 8, 8]               0\n",
      "          Conv2d-159           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-161           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-162           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-163            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-165            [-1, 512, 8, 8]               0\n",
      "          Conv2d-166            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-168            [-1, 512, 8, 8]               0\n",
      "          Conv2d-169           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-171           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-172           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 374.27\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 472.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_conv_50 = torchvision.models.resnet50(pretrained=True)\n",
    "generator = GeneratorNet(model_conv_50)\n",
    "summary(generator.cuda(), (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_G = torch.optim.Adam(  itertools.filterfalse(lambda x: x.requires_grad, itertools.chain(generator.parameters(), generator_2.parameters())),\n",
    "                   lr=0.001,\n",
    "                   betas=(0.5, 0.999)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch kernel",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
